\section{Introduction}

\if 0
\begin{comment}
	\emph{PDS:}
	Our goal is to motivate and sketch out our work.
	
	At the moment, I've simply dropped in a copy of our proposal.
	Even if those ideas suffice, we clearly need to adjust the text since
	we're now talking about what we have done rather
	than what we propose to do.
	
	Let's consider improving the ideas.
	
	I want to move away from
	TCG-style attestation to the more general problem of
	\emph{authenticating a remote application}.
	Identifying
	all of the software running on a machine may well uniquely
	identify the machine.
	Authentication without inherently leaking identity enables
	attestation. What other protocols does it enable?
	Voting protocols?
\end{comment}
\fi

We implemented Direct Anonymous Attestation~(DAA) on top of
a member of the IBM~4758 family of
cryptographic coprocessors~\cite{daa,smith:design}.

Attestation is a core concept in so-called trusted computing.
It enables trust decisions based on the identity of a machine
and its software stack.
Why identity?
Consider the following scenario.
Suppose server $S$ houses content $C$ and wants to
only ever release $C$ to a trusted application $A$;
for example, $S$ might supply music online,
$C$ might comprise songs,
and $A$ might be a trusted application that
lets its users listen to---but not copy---their purchases.
Certainly, $S$ would employ cryptographic protocols to protect
its content during download, but what about \emph{after} download?
How does $S$ ensure it's really talking to $A$? Moreover, how does
it ensure that no other software running alongside $A$ makes an illicit
copy of $C$?
Attestation attempts to mitigate such concerns; for example,
prior to sending $C$, the server $S$ might identify all of the
software running alongside $A$ to ensure that only ``trustworthy'' programs
are running.

As this scenario suggests, we are concerned with \emph{remote} attestation.
Remote attestation involves authenticating a trusted component (e.g., a trusted platform module---TPM)
on a remote machine prior to running an attestation protocol
with it.
Authentication matters: $S$ would like to know that when it performs a remote attestation,
its peer is \emph{honest}.
By communicating with a TPM, $S$ avoids trusting
the rest of a user's machine.
But authentication poses a problem: A TPM's identity serves as
\emph{personally identifying information.}
In our scenario, for example, if remote attestation reveals a TPM's identity, then
online companies might misuse that information to track a user and profile
her preferences.

DAA authenticates a TPM
while offering anonymity guarantees.
DAA performs the necessary authentication \emph{without} revealing the TPM's identity,
sending $S$ a zero-knowledge proof instead.

In this project, we adapt DAA to work with an IBM secure coprocessor
rather than a TPM.
Such coprocessors serve as dedicated machines, 
designed to run arbitrary application-specific
code in a controlled, secure environment.
The TPM specification takes a far less
interesting and (in the long-term) less maintainable approach to
secure coprocessing: One size fits all.
More important, the IBM coprocessors have been verified to FIPS~140-1 Level~4.
Among other things, this means they offer laboratory-tested physical security against
environmental attacks.
Keys and other sensitive data stored in an IBM coprocessor's battery-backed RAM
are automatically `zeroized' when such attacks are detected~\cite{smith:fips}.
To our knowledge, no TPM has been so verified.

Our contributions include
\begin{itemize}
\item An implementation of DAA for the IBM~4758 family of cryptographic coprocessors.
To the best of our knowledge, no out-of-the-box implementations exist.
This should enable trusted computing systems to harness the numerous hardware and software features provided by cryptocards.
As we discuss in Section~\ref{sec:impl}, we provide implementations in ML and C.

\item Simplification.
Due to the hardware limitations of the TPM, traditional DAA implementations offload expensive computations to the relatively more powerful processor of the host machine.
However, the results of offloaded computations have to be verified by the TPM since the host is not trusted.
In our model, we eliminate the distinction between the host and the cryptocard. 
\end{itemize}

In~\secref{daa}, we describe DAA.
In~\secref{background}, we elaborate by describing the
cryptographic building blocks used in DAA.
In~\secref{impl}, we describe our implementation.
A brief appendix discusses our individual contributions.
